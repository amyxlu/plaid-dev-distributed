_target_: plaid.vqvae.TransformerVQVAE

in_dim: 1024

vqvae_h_dim: 512
vqvae_res_h_dim: 512
vqvae_n_res_layers: 12 
vqvae_n_embeddings: 1024
vqvae_kernel: 4
vqvae_stride: 2
vqvae_embedding_dim: 64
vqvae_beta: 0.25

patch_len: 8

transformer_hidden_act: "gelu"
transformer_intermediate_size: 3072
transformer_num_attention_heads: 16
transformer_num_hidden_layers: 12
transformer_position_embedding_type: "absolute"

lr: 5e-4
lr_beta1: 0.9
lr_beta2: 0.999
lr_sched_type: "constant"
lr_num_warmup_steps: 0
lr_num_training_steps: 100_000_000
lr_num_cycles: 1 

sequence_decoder_weight: 1.
structure_decoder_weight: 0.
latent_reconstruction_method: "unnormalized_x_recons"
log_reconstructed_sequences: True