# @package _global_

# make sure that 1024 / downproj_factor = e_dim
defaults:
  - override /datamodule: uniref_subset_sharded

datamodule:
  batch_size: 64
  seq_len: 512 
  num_workers: 1

logger:
  name: fsq-88888888
  tags: fsq

hourglass:
  n_e: 128 
  e_dim: 64
  use_quantizer: "fsq"
  fsq_levels: [8, 8, 8, 8, 8, 8, 8, 8]
  downproj_factor: 128
  lr: 3e-5
  lr_num_warmup_steps: 5000

trainer:
  precision: "bf16-mixed"
  log_every_n_steps: 20
  gradient_clip_val: 0.5
