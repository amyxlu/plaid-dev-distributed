{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "069dd14d-c22d-4561-bd01-11c7e950dcb2",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5650be11-405d-4851-b4d3-1513433239a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "891c3eea-bcfb-4dfd-8cf5-0bb3a1ea5ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "import torch\n",
    "from plaid.datasets import CATHShardedDataModule, CATHStructureDataModule\n",
    "from plaid.esmfold.misc import batch_encode_sequences\n",
    "from plaid.utils import LatentScaler\n",
    "from plaid.losses.modules import SequenceAuxiliaryLoss, BackboneAuxiliaryLoss\n",
    "from plaid.proteins import LatentToStructure, LatentToSequence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62ca9cb3-2120-4211-8abd-7300d04dada1",
   "metadata": {},
   "source": [
    "# Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "865afd3b-75f7-4687-bdb1-37a108cef252",
   "metadata": {},
   "outputs": [],
   "source": [
    "shard_dir = \"/homefs/home/lux70/storage/data/rocklin/shards/\"\n",
    "pdb_dir = \"/homefs/home/lux70/storage/data/rocklin/structures/\" \n",
    "# shard_dir = \"/homefs/home/lux70/storage/data/cath/shards/\"\n",
    "# pdb_dir = \"/homefs/home/lux70/storage/data/cath/dompdb/\"\n",
    "\n",
    "embedder = \"esmfold\"\n",
    "D = 1024 if embedder == \"esmfold\" else 320\n",
    "\n",
    "# dm = CATHShardedDataModule(\n",
    "#     storage_type=\"hdf5\",\n",
    "#     shard_dir=shard_dir,\n",
    "#     embedder=embedder,\n",
    "#     seq_len=256,\n",
    "#     batch_size=512\n",
    "# )\n",
    "dm = CATHStructureDataModule(\n",
    "    shard_dir=shard_dir,\n",
    "    pdb_path_dir=pdb_dir,\n",
    "    embedder=embedder,\n",
    "    seq_len=256,\n",
    "    batch_size=16\n",
    ")\n",
    "dm.setup()\n",
    "train_dataloader = dm.train_dataloader()\n",
    "val_dataloader = dm.val_dataloader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a23122a2-60f1-4f6c-acc6-4ad9c19587d0",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/homefs/home/lux70/storage/data/rocklin/structures/HHH_rd3_0202.pdb_buryD'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28miter\u001b[39m(train_dataloader))\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.12/site-packages/torch/utils/data/dataloader.py:631\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    630\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 631\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_data()\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    635\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.12/site-packages/torch/utils/data/dataloader.py:675\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    673\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    674\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 675\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_fetcher\u001b[38;5;241m.\u001b[39mfetch(index)  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    676\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    677\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.12/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/code/plaid/plaid/datasets.py:174\u001b[0m, in \u001b[0;36mCATHStructureDataset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    172\u001b[0m pdb_id, (emb, seq) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget(idx)\n\u001b[1;32m    173\u001b[0m pdb_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpdb_path_dir \u001b[38;5;241m/\u001b[39m pdb_id\n\u001b[0;32m--> 174\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(pdb_path, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m    175\u001b[0m     pdb_str \u001b[38;5;241m=\u001b[39m f\u001b[38;5;241m.\u001b[39mread()\n\u001b[1;32m    176\u001b[0m \u001b[38;5;66;03m# try:\u001b[39;00m\n\u001b[1;32m    177\u001b[0m \u001b[38;5;66;03m#     structure_features = self.structure_featurizer(pdb_str, self.max_seq_len)\u001b[39;00m\n\u001b[1;32m    178\u001b[0m \u001b[38;5;66;03m#     return emb, seq, structure_features \u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    182\u001b[0m \u001b[38;5;66;03m#         f.write(f\"{pdb_id}\\n\")\u001b[39;00m\n\u001b[1;32m    183\u001b[0m \u001b[38;5;66;03m#     pass\u001b[39;00m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/homefs/home/lux70/storage/data/rocklin/structures/HHH_rd3_0202.pdb_buryD'"
     ]
    }
   ],
   "source": [
    "batch = next(iter(train_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "65622f9c-b966-4834-a92a-4efaedf58285",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['aatype', 'between_segment_residues', 'domain_name', 'residue_index', 'seq_length', 'sequence', 'all_atom_positions', 'all_atom_mask', 'resolution', 'is_distillation', 'mask', 'rigidgroups_gt_frames', 'rigidgroups_gt_exists', 'rigidgroups_group_exists', 'rigidgroups_group_is_ambiguous', 'rigidgroups_alt_gt_frames', 'backbone_rigid_tensor', 'backbone_rigid_mask'])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch[-1].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "264a5636-3d63-457b-ae8d-d91a8bf2d057",
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_scaler = LatentScaler(lm_embedder_type=embedder)\n",
    "# sequence_constructor = LatentToSequence()\n",
    "# sequence_constructor.to(\"cuda\")\n",
    "# seq_loss = SequenceAuxiliaryLoss(sequence_constructor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "13eeb53d-8520-4af3-b0fd-081f0dcdded1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from plaid.losses.modules import BackboneAuxiliaryLoss\n",
    "structure_constructor = LatentToStructure()\n",
    "structure_constructor.to('cuda')\n",
    "structure_loss_fn = BackboneAuxiliaryLoss(structure_constructor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90ee1892-7dba-4758-867e-7f8e058933ab",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "22c1557a-7e57-4d9f-94da-153815624c0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, einsum\n",
    "import torch.nn.functional as F\n",
    "from einops import rearrange, reduce, repeat\n",
    "\n",
    "# helpers\n",
    "\n",
    "def exists(val):\n",
    "    return val is not None\n",
    "\n",
    "def default(val, d):\n",
    "    return val if exists(val) else d\n",
    "\n",
    "def pad_to_multiple(tensor, multiple, dim = -1, value = 0):\n",
    "    seq_len = tensor.shape[dim]\n",
    "    m = seq_len / multiple\n",
    "    if m.is_integer():\n",
    "        return tensor\n",
    "    remainder = math.ceil(m) * multiple - seq_len\n",
    "    pad_offset = (0,) * (-1 - dim) * 2\n",
    "    return F.pad(tensor, (*pad_offset, 0, remainder), value = value)\n",
    "\n",
    "def cast_tuple(val, depth = 1):\n",
    "    return val if isinstance(val, tuple) else ((val,) * depth)\n",
    "\n",
    "# factory\n",
    "\n",
    "def get_hourglass_transformer(\n",
    "    dim,\n",
    "    *,\n",
    "    depth,\n",
    "    shorten_factor,\n",
    "    attn_resampling,\n",
    "    updown_sample_type,\n",
    "    **kwargs\n",
    "):\n",
    "    assert isinstance(depth, int) or (isinstance(depth, tuple)  and len(depth) == 3), 'depth must be either an integer or a tuple of 3, indicating (pre_transformer_depth, <nested-hour-glass-config>, post_transformer_depth)'\n",
    "    assert not (isinstance(depth, int) and shorten_factor), 'there does not need to be a shortening factor when only a single transformer block is indicated (depth of one integer value)'\n",
    "\n",
    "    if isinstance(depth, int):\n",
    "        return Transformer(dim = dim, depth = depth, **kwargs)\n",
    "\n",
    "    return HourglassTransformer(dim = dim, depth = depth, shorten_factor = shorten_factor, attn_resampling = attn_resampling, updown_sample_type = updown_sample_type, **kwargs)\n",
    "\n",
    "# up and down sample classes\n",
    "\n",
    "class NaiveDownsample(nn.Module):\n",
    "    def __init__(self, shorten_factor):\n",
    "        super().__init__()\n",
    "        self.shorten_factor = shorten_factor\n",
    "\n",
    "    def forward(self, x):\n",
    "        return reduce(x, 'b (n s) d -> b n d', 'mean', s = self.shorten_factor)\n",
    "\n",
    "class NaiveUpsample(nn.Module):\n",
    "    def __init__(self, shorten_factor):\n",
    "        super().__init__()\n",
    "        self.shorten_factor = shorten_factor\n",
    "\n",
    "    def forward(self, x):\n",
    "        return repeat(x, 'b n d -> b (n s) d', s = self.shorten_factor)\n",
    "\n",
    "class LinearDownsample(nn.Module):\n",
    "    def __init__(self, dim, shorten_factor):\n",
    "        super().__init__()\n",
    "        self.proj = nn.Linear(dim * shorten_factor, dim)\n",
    "        self.shorten_factor = shorten_factor\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = rearrange(x, 'b (n s) d -> b n (s d)', s = self.shorten_factor)\n",
    "        return self.proj(x)\n",
    "\n",
    "class LinearUpsample(nn.Module):\n",
    "    def __init__(self, dim, shorten_factor):\n",
    "        super().__init__()\n",
    "        self.proj = nn.Linear(dim, dim * shorten_factor)\n",
    "        self.shorten_factor = shorten_factor\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.proj(x)\n",
    "        return rearrange(x, 'b n (s d) -> b (n s) d', s = self.shorten_factor)\n",
    "\n",
    "# classes\n",
    "\n",
    "class PreNormResidual(nn.Module):\n",
    "    def __init__(self, dim, fn):\n",
    "        super().__init__()\n",
    "        self.norm = nn.LayerNorm(dim)\n",
    "        self.fn = fn\n",
    "\n",
    "    def forward(self, x, **kwargs):\n",
    "        return self.fn(self.norm(x), **kwargs) + x\n",
    "\n",
    "class Attention(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        dim,\n",
    "        heads = 8,\n",
    "        dim_head = 64,\n",
    "        dropout = 0.,\n",
    "        causal = False\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.heads = heads\n",
    "        self.causal = causal\n",
    "        self.scale = dim_head ** -0.5\n",
    "        inner_dim = heads * dim_head\n",
    "\n",
    "        self.to_q = nn.Linear(dim, inner_dim, bias = False)\n",
    "        self.to_kv = nn.Linear(dim, inner_dim * 2, bias = False)\n",
    "        self.to_out = nn.Linear(inner_dim, dim)\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x, context = None, mask = None):\n",
    "        h, device = self.heads, x.device\n",
    "        kv_input = default(context, x)\n",
    "\n",
    "        q, k, v = self.to_q(x), *self.to_kv(kv_input).chunk(2, dim = -1)\n",
    "        q, k, v = map(lambda t: rearrange(t, 'b n (h d) -> b h n d', h = h), (q, k, v))\n",
    "\n",
    "        q = q * self.scale\n",
    "\n",
    "        sim = einsum('b h i d, b h j d -> b h i j', q, k)\n",
    "        mask_value = -torch.finfo(sim.dtype).max\n",
    "\n",
    "        if exists(mask):\n",
    "            mask = rearrange(mask, 'b j -> b () () j')\n",
    "            sim = sim.masked_fill(~mask, mask_value)\n",
    "\n",
    "        if self.causal:\n",
    "            i, j = sim.shape[-2:]\n",
    "            mask = torch.ones(i, j, device = device, dtype = torch.bool).triu_(j - i + 1)\n",
    "            mask = rearrange(mask, 'i j -> () () i j')\n",
    "            sim = sim.masked_fill(mask, mask_value)\n",
    "\n",
    "        attn = sim.softmax(dim = -1)\n",
    "        attn = self.dropout(attn)\n",
    "\n",
    "        out = einsum('b h i j, b h j d -> b h i d', attn, v)\n",
    "        out = rearrange(out, 'b h n d -> b n (h d)', h = h)\n",
    "        return self.to_out(out)\n",
    "\n",
    "def FeedForward(dim, mult = 4, dropout = 0.):\n",
    "    return nn.Sequential(\n",
    "        nn.Linear(dim, dim * mult),\n",
    "        nn.GELU(),\n",
    "        nn.Dropout(dropout),\n",
    "        nn.Linear(dim * mult, dim)\n",
    "    )\n",
    "\n",
    "# transformer classes\n",
    "\n",
    "class Transformer(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        dim,\n",
    "        *,\n",
    "        depth,\n",
    "        causal = False,\n",
    "        heads = 8,\n",
    "        dim_head = 64,\n",
    "        attn_dropout = 0.,\n",
    "        ff_mult = 4,\n",
    "        ff_dropout = 0.,\n",
    "        norm_out = False\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.layers = nn.ModuleList([])\n",
    "\n",
    "        for _ in range(depth):\n",
    "            self.layers.append(nn.ModuleList([\n",
    "                PreNormResidual(dim, Attention(dim, heads = heads, dim_head = dim_head, dropout = attn_dropout, causal = causal)),\n",
    "                PreNormResidual(dim, FeedForward(dim, mult = ff_mult, dropout = ff_dropout))\n",
    "            ]))\n",
    "\n",
    "        self.norm = nn.LayerNorm(dim) if norm_out else nn.Identity()\n",
    "\n",
    "    def forward(self, x, context = None, mask = None):\n",
    "        for attn, ff in self.layers:\n",
    "            x = attn(x, context = context, mask = mask)\n",
    "            x = ff(x)\n",
    "\n",
    "        return self.norm(x)\n",
    "\n",
    "class HourglassTransformer(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        dim,\n",
    "        *,\n",
    "        depth,\n",
    "        shorten_factor = 2,\n",
    "        attn_resampling = True,\n",
    "        updown_sample_type = 'naive',\n",
    "        heads = 8,\n",
    "        dim_head = 64,\n",
    "        causal = False,\n",
    "        norm_out = False\n",
    "    ):\n",
    "        super().__init__()\n",
    "        assert len(depth) == 3, 'depth should be a tuple of length 3'\n",
    "        assert updown_sample_type in {'naive', 'linear'}, 'downsample / upsample type must be either naive (average pool and repeat) or linear (linear projection and reshape)'\n",
    "\n",
    "        pre_layers_depth, valley_depth, post_layers_depth = depth\n",
    "\n",
    "        if isinstance(shorten_factor, (tuple, list)):\n",
    "            shorten_factor, *rest_shorten_factor = shorten_factor\n",
    "        elif isinstance(valley_depth, int):\n",
    "            shorten_factor, rest_shorten_factor = shorten_factor, None\n",
    "        else:\n",
    "            shorten_factor, rest_shorten_factor = shorten_factor, shorten_factor\n",
    "\n",
    "        transformer_kwargs = dict(\n",
    "            dim = dim,\n",
    "            heads = heads,\n",
    "            dim_head = dim_head\n",
    "        )\n",
    "\n",
    "        self.causal = causal\n",
    "        self.shorten_factor = shorten_factor\n",
    "\n",
    "        if updown_sample_type == 'naive':\n",
    "            self.downsample = NaiveDownsample(shorten_factor)\n",
    "            self.upsample   = NaiveUpsample(shorten_factor)\n",
    "        elif updown_sample_type == 'linear':\n",
    "            self.downsample = LinearDownsample(dim, shorten_factor)\n",
    "            self.upsample   = LinearUpsample(dim, shorten_factor)\n",
    "        else:\n",
    "            raise ValueError(f'unknown updown_sample_type keyword value - must be either naive or linear for now')\n",
    "\n",
    "        self.valley_transformer = get_hourglass_transformer(\n",
    "            shorten_factor = rest_shorten_factor,\n",
    "            depth = valley_depth,\n",
    "            attn_resampling = attn_resampling,\n",
    "            updown_sample_type = updown_sample_type,\n",
    "            causal = causal,\n",
    "            **transformer_kwargs\n",
    "        )\n",
    "\n",
    "        self.attn_resampling_pre_valley = Transformer(depth = 1, **transformer_kwargs) if attn_resampling else None\n",
    "        self.attn_resampling_post_valley = Transformer(depth = 1, **transformer_kwargs) if attn_resampling else None\n",
    "\n",
    "        self.pre_transformer = Transformer(depth = pre_layers_depth, causal = causal, **transformer_kwargs)\n",
    "        self.post_transformer = Transformer(depth = post_layers_depth, causal = causal, **transformer_kwargs)\n",
    "        self.norm_out = nn.LayerNorm(dim) if norm_out else nn.Identity()\n",
    "\n",
    "    def forward(self, x, mask = None):\n",
    "        # b : batch, n : sequence length, d : feature dimension, s : shortening factor\n",
    "\n",
    "        s, b, n = self.shorten_factor, *x.shape[:2]\n",
    "\n",
    "        # top half of hourglass, pre-transformer layers\n",
    "\n",
    "        x = self.pre_transformer(x, mask = mask)\n",
    "\n",
    "        # pad to multiple of shortening factor, in preparation for pooling\n",
    "\n",
    "        x = pad_to_multiple(x, s, dim = -2)\n",
    "\n",
    "        if exists(mask):\n",
    "            padded_mask = pad_to_multiple(mask, s, dim = -1, value = False)\n",
    "\n",
    "        # save the residual, and for \"attention resampling\" at downsample and upsample\n",
    "\n",
    "        x_residual = x.clone()\n",
    "\n",
    "        # if autoregressive, do the shift by shortening factor minus one\n",
    "\n",
    "        if self.causal:\n",
    "            shift = s - 1\n",
    "            x = F.pad(x, (0, 0, shift, -shift), value = 0.)\n",
    "\n",
    "            if exists(mask):\n",
    "                padded_mask = F.pad(padded_mask, (shift, -shift), value = False)\n",
    "\n",
    "        # naive average pool\n",
    "\n",
    "        downsampled = self.downsample(x)\n",
    "\n",
    "        if exists(mask):\n",
    "            downsampled_mask = reduce(padded_mask, 'b (n s) -> b n', 'sum', s = s) > 0\n",
    "        else:\n",
    "            downsampled_mask = None\n",
    "\n",
    "        # pre-valley \"attention resampling\" - they have the pooled token in each bucket attend to the tokens pre-pooled\n",
    "\n",
    "        if exists(self.attn_resampling_pre_valley):\n",
    "            if exists(mask):\n",
    "                attn_resampling_mask = rearrange(padded_mask, 'b (n s) -> (b n) s', s = s)\n",
    "            else:\n",
    "                attn_resampling_mask = None\n",
    "\n",
    "            downsampled = self.attn_resampling_pre_valley(\n",
    "                rearrange(downsampled, 'b n d -> (b n) () d'),\n",
    "                rearrange(x, 'b (n s) d -> (b n) s d', s = s),\n",
    "                mask = attn_resampling_mask\n",
    "            )\n",
    "\n",
    "            downsampled = rearrange(downsampled, '(b n) () d -> b n d', b = b)\n",
    "\n",
    "        # the \"valley\" - either a regular transformer or another hourglass\n",
    "\n",
    "        x = self.valley_transformer(downsampled, mask = downsampled_mask)\n",
    "\n",
    "        valley_out = x.clone()\n",
    "\n",
    "        # naive repeat upsample\n",
    "\n",
    "        x = self.upsample(x)\n",
    "\n",
    "        # add the residual\n",
    "\n",
    "        x = x + x_residual\n",
    "\n",
    "        # post-valley \"attention resampling\"\n",
    "\n",
    "        if exists(self.attn_resampling_post_valley):\n",
    "            x = self.attn_resampling_post_valley(\n",
    "                rearrange(x, 'b (n s) d -> (b n) s d', s = s),\n",
    "                rearrange(valley_out, 'b n d -> (b n) () d')\n",
    "            )\n",
    "\n",
    "            x = rearrange(x, '(b n) s d -> b (n s) d', b = b)\n",
    "\n",
    "        # bring sequence back to original length, if it were padded for pooling\n",
    "\n",
    "        x = x[:, :n]\n",
    "\n",
    "        # post-valley transformers\n",
    "\n",
    "        x = self.post_transformer(x, mask = mask)\n",
    "        return self.norm_out(x)\n",
    "\n",
    "transformer = get_hourglass_transformer(\n",
    "    dim = D,                     # feature dimension\n",
    "    heads = 8,                      # attention heads\n",
    "    dim_head = 64,                  # dimension per attention head\n",
    "    shorten_factor = 2,             # shortening factor\n",
    "    depth = (4, 2, 4),              # tuple of 3, standing for pre-transformer-layers, valley-transformer-layers (after downsample), post-transformer-layers (after upsample) - the valley transformer layers can be yet another nested tuple, in which case it will shorten again recursively\n",
    "    attn_resampling = True,\n",
    "    updown_sample_type = \"naive\",\n",
    "    causal = True,\n",
    "    norm_out = True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afed71e7-c59e-4b32-8016-97a94ef91d92",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d35eaff9-b00d-4e9d-9284-cbe7a2f8168e",
   "metadata": {},
   "source": [
    "## Sample Batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f1655ed6-be27-430e-8827-e141e3ddef0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 256, 1024])\n",
      "torch.Size([16, 256])\n",
      "tensor(1.3380, device='cuda:0') tensor(71.8841, device='cuda:0')\n",
      "tensor(-0.0011, device='cuda:0') tensor(0.2243, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "batch = next(iter(train_dataloader))\n",
    "\n",
    "sequences = batch[1]\n",
    "tokens, mask, _, _, _ = batch_encode_sequences(sequences)\n",
    "\n",
    "x = batch[0]\n",
    "if embedder != \"esmfold\":\n",
    "    x = x[:, 1:-1, :]\n",
    "mask = mask.bool()\n",
    "print(x.shape)\n",
    "print(mask.shape)\n",
    "\n",
    "device = \"cuda\"\n",
    "transformer = transformer.to(device)\n",
    "x, mask = x.to(device), mask.to(device)\n",
    "print(x.mean(), x.std())\n",
    "\n",
    "x = latent_scaler.scale(x)\n",
    "print(x.mean(), x.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5a32f8ce-3ea1-4a15-bb15-5b90e127ab2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = transformer(x, mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "213b5dac-3e7f-48e6-9d30-269c2cb49bd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 256, 1024])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f9a5e5b8-4581-4f57-b578-587981fa2345",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating structure from latents\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor(0.9506, device='cuda:0'), {'backbone_loss': 0.9506101012229919})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "structure_loss_fn(output, batch[-1], batch[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c503dcfa-4525-4a5f-bce8-372b8293c623",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d0fb6d2d-6c4a-4e8c-9240-ef5d63f7c019",
   "metadata": {},
   "source": [
    "### Reconstruct Sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ce7ac53-04f8-45a9-9881-8812c04f8cfb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f13142d3-3d8b-4945-966e-d3ea7cd08bce",
   "metadata": {},
   "outputs": [],
   "source": [
    "unnormalized_x_recons = latent_scaler.unscale(output)\n",
    "sequence_constructor = LatentToSequence()\n",
    "probs, _, strs = sequence_constructor.to_sequence(unnormalized_x_recons, mask, return_logits=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d2e7f7d-6ff0-41be-8a15-f2947963d6d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(unnormalized_x_recons.mean(), unnormalized_x_recons.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccb62862-42f4-426f-b8f6-c2a8edc405f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "strs[:10]  # random strings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18d3317f-7910-4f08-9ade-87d1aa08be4f",
   "metadata": {},
   "source": [
    "## Train Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22956a45-e3ee-449f-bef0-30467a2d610e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm, trange\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import AdamW\n",
    "\n",
    "optimizer = AdamW(transformer.parameters(), lr=1e-4)\n",
    "n_epochs = 100\n",
    "\n",
    "losses = []\n",
    "\n",
    "for epoch in trange(n_epochs): \n",
    "    for i, batch in enumerate(train_dataloader):\n",
    "        sequences = batch[1]\n",
    "        tokens, mask, _, _, _ = batch_encode_sequences(sequences)\n",
    "\n",
    "        x = batch[0]\n",
    "        if embedder != \"esmfold\":\n",
    "            x = x[:, 1:-1, :]\n",
    "        else:\n",
    "            x = latent_scaler.scale(x)\n",
    "        mask = mask.bool()\n",
    "        x, mask = x.to(device), mask.to(device)\n",
    "        \n",
    "        output = transformer(x, mask)\n",
    "        recons_loss = F.mse_loss(x, output)\n",
    "        if i % 50 == 0:\n",
    "            print(loss.item()) \n",
    "\n",
    "        unnormalized_x_recons = latent_scaler.unscale(output)\n",
    "        \n",
    "        logits, _, strs = sequence_constructor.to_sequence(unnormalized_x_recons, mask, return_logits=True)\n",
    "    \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ed73124-df33-40d0-9091-14d34c66bb2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec56d600-c7a2-4d2a-9209-dbd385cd5a0e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
