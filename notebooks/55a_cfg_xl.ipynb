{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8be77fb2-2be4-4ef5-bcff-c337ac2e0f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cf5d6a4-43cc-43cd-b2cd-32d85ba411eb",
   "metadata": {},
   "source": [
    "# Load EMA weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "40340dd1-691e-46a9-a7a4-89764ae70232",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from omegaconf import OmegaConf\n",
    "\n",
    "import torch\n",
    "from plaid.diffusion import FunctionOrganismDiffusion\n",
    "from plaid.denoisers import FunctionOrganismDiT, DenoiserKwargs\n",
    "from plaid.constants import COMPRESSION_INPUT_DIMENSIONS, COMPRESSION_SHORTEN_FACTORS\n",
    "\n",
    "device = torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d41fe821-9853-4dac-8770-7ad43913f72c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = \"4hdab8dn\"\n",
    "\n",
    "ckpt_dir = Path(\"/data/lux70/plaid/checkpoints/plaid-compositional\") \n",
    "model_path = ckpt_dir / model_id / \"last.ckpt\"\n",
    "config_path = ckpt_dir / model_id / \"config.yaml\"\n",
    "\n",
    "cfg = OmegaConf.load(config_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0d0ee233-db93-413c-9ad8-3d64002782ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "compression_model_id = cfg['compression_model_id']\n",
    "shorten_factor = COMPRESSION_SHORTEN_FACTORS[compression_model_id]\n",
    "input_dim = COMPRESSION_INPUT_DIMENSIONS[compression_model_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0ccb6306-1595-415f-972a-f2e26c8f0855",
   "metadata": {},
   "outputs": [],
   "source": [
    "denoiser_kwargs = cfg.denoiser\n",
    "denoiser_kwargs.pop(\"_target_\")\n",
    "denoiser = FunctionOrganismDiT(**denoiser_kwargs, input_dim=input_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "893d53c5-fb33-4ba3-abf0-f5fcef079c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lask.ckpt automatically links to the EMA\n",
    "\n",
    "ckpt = torch.load(model_path)\n",
    "# ckpt.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "339644e5-2ad5-4c13-a861-b0451aa896dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "mod_state_dict = {}\n",
    "for k, v in ckpt['state_dict'].items():\n",
    "    if k[:16] == \"model._orig_mod.\":\n",
    "        mod_state_dict[k[16:]] = v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3db302af-0823-4253-87bd-2759f57bba5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "denoiser.load_state_dict(mod_state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "de95b1ca-a6a7-4577-a627-3a4e440d28c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "diffusion_kwargs = cfg.diffusion\n",
    "diffusion_kwargs.pop(\"_target_\")\n",
    "\n",
    "# diffusion_kwargs['beta_scheduler_name'] = \"sigmoid\"\n",
    "diffusion_kwargs['sampling_timesteps'] = 500\n",
    "\n",
    "diffusion = FunctionOrganismDiffusion(model=denoiser,**diffusion_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "11c8b285-5450-4c5b-a524-5bd16104f47f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using tanh layer at bottleneck...\n",
      "Finished loading HPCT model with shorten factor 2 and 32 channel dimensions.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating ESMFold...\n",
      "ESMFold model loaded in 41.65 seconds.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<cheap.proteins.LatentToStructure at 0x7f46d321ac50>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from cheap.pretrained import load_model_from_id\n",
    "cheap_model = load_model_from_id(compression_model_id)\n",
    "_ = cheap_model.to(device)\n",
    "\n",
    "from cheap.proteins import LatentToSequence,LatentToStructure\n",
    "latent_to_sequence = LatentToSequence()\n",
    "latent_to_sequence.to(device)\n",
    "\n",
    "latent_to_structure = LatentToStructure()\n",
    "latent_to_structure.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80da3b78-1ae3-43d5-bcfb-e1debeeb2b88",
   "metadata": {},
   "source": [
    "# Sample\n",
    "Human, carbohydrate metabolic process:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8dbb148c-1816-460f-a511-050f4b9ac60c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# organism_idx = org_df[org_df.organism_id == \"HUMAN\"].organism_index.iloc[0]\n",
    "# function_idx = go_df[go_df.GO_term == \"carbohydrate metabolic process\"].GO_idx.iloc[0]\n",
    "# print(organism_idx, function_idx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ef5574ef-a2a4-4ed4-a8c0-ef6046ded4eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\")\n",
    "diffusion = diffusion.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dbfd8cdc-0b38-4e42-9896-9bceae605613",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0506a19578ae49e78dc70c6785ae4d49",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sampling loop time step:   0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from plaid.datasets import NUM_ORGANISM_CLASSES, NUM_FUNCTION_CLASSES\n",
    "\n",
    "N, L = 32, 128\n",
    "shape = (N, L, input_dim)\n",
    "\n",
    "organism_idx = 0\n",
    "function_idx = 0\n",
    "\n",
    "organism_y_idxs = torch.full((N,), organism_idx)\n",
    "function_y_idxs = torch.full((N,), function_idx)\n",
    "\n",
    "cond_scale = 0\n",
    "\n",
    "diffusion.sampling_timesteps=500\n",
    "diffusion\n",
    "sampled_latent = diffusion.ddim_sample_loop(shape, organism_idx, function_idx, return_all_timesteps=True, cond_scale=cond_scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1cc49c1b-4349-43c0-bbc2-86bc37c22029",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 501, 128, 32])\n",
      "torch.Size([32, 128, 32])\n",
      "tensor(1.0084, device='cuda:0') tensor(-1.0432, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(sampled_latent.shape)\n",
    "final_sample = sampled_latent[:, -1, :, :]\n",
    "print(final_sample.shape)\n",
    "\n",
    "print(final_sample.max(), final_sample.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6be3f51f-c486-4b19-b8e9-449c810ddad9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-1.1275, device='cuda:0') tensor(1.2699, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "sampled_uncompressed = cheap_model.decode(final_sample, downsampled_mask=None)\n",
    "print(sampled_uncompressed.min(), sampled_uncompressed.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dbcf8ec3-7afc-48ae-b0d5-d19ded99b383",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle as pkl\n",
    "# with open(\"test_sample.pkl\", \"wb\") as f:\n",
    "#     pkl.dump(sampled_uncompressed,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8e77d77c-ee26-41ee-a29b-67b3c9777136",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cheap.utils import LatentScaler\n",
    "latent_scaler = LatentScaler()\n",
    "sampled_unscaled = latent_scaler.unscale(sampled_uncompressed) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "36492297-c8cc-44f2-8198-88b8e1223b3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 256, 1024])\n",
      "tensor(2944.7717, device='cuda:0') tensor(-878.1273, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(sampled_unscaled.shape)\n",
    "print(sampled_unscaled.max(), sampled_unscaled.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4ebf6908-d86b-4266-a9a9-65c020f2c8cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences = latent_to_sequence.to_sequence(sampled_unscaled)[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c07e3c4f-692f-435d-b495-d842e2653577",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['VGIDAGGSRTDIWLLDRHRHGDVARALGPSMPRHLSAAADAVIDALLALSDRVDPADVAALVVGSAGITSSDVVAALRPALARWSRRAGADPATVTRDSELALAAAGVADGVIVQPGTGLIGVALTQGQELREQANGHGMLMGDEGSGDWVGQRAAVAILRVAHDGRADPLVANPLSAAVLEVAGGDDATKSAIEAGVSALARGIGTTAALAGPGFQLVLTGAVLSSDPGWREEAARMIARLTGVTGGRVLTTADG',\n",
       " 'IAADLDGTLLVGNNRVSGEVRAAVGAMHHAGVLPAVCTGRAYPLMRHEHDVLGFCSPVMSTNGAFVYNLRTHSTLHVERLDPELLQVLAALCERNRHTRIVLSTAHGIWFNPEFERVKHIPPRYFQHRPSSAELSPESNDRIHQIIASNTEALTQYLRGVYWPALATHMHVQDSDVHWVEVTLGGTDKGSALAVLRAHLGISANNVASVGDHFNDAEMLEQAGLGVAMGNAPPQIKAHADYVAGAIVDKGVLSALK',\n",
       " 'KSLFAETIAFIKQQGASTVVVIDPCEAVSQESIADLMEGELENVDIYKRQLEEERGNPATVIIKLMKIMEDAEMQTGKGKCAIILFGNGSGVQVYLGYTHHLDIPVFTGHIAGCEYIKALTVQHVLNEIPDELILHIDVRVLKDLIKASISSHMDERVHSSTIHQIAAQQSDAIFAKLFGEGIPFNQGKFNAPLLTKLKHDFINVYIERAVDIMLESMLPHFEKTIIGIAQSAVTLFHMLLLAETYNDVYYHGVGL']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ab9c6666-1bee-41b8-a7be-5b408aa3aa0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(Generating structure):   0%|                                                                                                                                     | 0/1 [01:03<?, ?it/s]\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 8.00 GiB. GPU ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m pdb_strs, raw_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mlatent_to_structure\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_structure\u001b[49m\u001b[43m(\u001b[49m\u001b[43msampled_unscaled\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_raw_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msequences\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msequences\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_recycles\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/code/cheap-proteins/src/cheap/proteins.py:343\u001b[0m, in \u001b[0;36mLatentToStructure.to_structure\u001b[0;34m(self, latent, sequences, num_recycles, batch_size, mask, return_raw_outputs, verbose, *args, **kwargs)\u001b[0m\n\u001b[1;32m    335\u001b[0m s_, aa_, mask_, residx_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(\n\u001b[1;32m    336\u001b[0m     \u001b[38;5;28mmap\u001b[39m(\n\u001b[1;32m    337\u001b[0m         \u001b[38;5;28;01mlambda\u001b[39;00m x: x[start : start \u001b[38;5;241m+\u001b[39m batch_size],\n\u001b[1;32m    338\u001b[0m         (latent, aatype, mask, residx),\n\u001b[1;32m    339\u001b[0m     )\n\u001b[1;32m    340\u001b[0m )\n\u001b[1;32m    342\u001b[0m \u001b[38;5;66;03m# Collect outputs\u001b[39;00m\n\u001b[0;32m--> 343\u001b[0m pdb_str, outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maa_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresidx_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_recycles\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    344\u001b[0m all_pdb_strs\u001b[38;5;241m.\u001b[39mextend(pdb_str)\n\u001b[1;32m    345\u001b[0m all_output_dicts\u001b[38;5;241m.\u001b[39mappend(outputs)\n",
      "File \u001b[0;32m~/micromamba/envs/plaid/lib/python3.10/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/code/cheap-proteins/src/cheap/proteins.py:280\u001b[0m, in \u001b[0;36mLatentToStructure.run_batch\u001b[0;34m(self, s_, aa_, mask_, residx_, num_recycles, *args, **kwargs)\u001b[0m\n\u001b[1;32m    277\u001b[0m residx_ \u001b[38;5;241m=\u001b[39m maybe_pad(residx_, L)\n\u001b[1;32m    279\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 280\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mesmfold\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfolding_trunk\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    281\u001b[0m \u001b[43m        \u001b[49m\u001b[43ms_s_0\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43ms_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    282\u001b[0m \u001b[43m        \u001b[49m\u001b[43ms_z_0\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mz_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    283\u001b[0m \u001b[43m        \u001b[49m\u001b[43maa\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maa_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    284\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresidx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresidx_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    285\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmask_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    286\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_recycles\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_recycles\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    287\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    288\u001b[0m pdb_str \u001b[38;5;241m=\u001b[39m output_to_pdb(output)\n\u001b[1;32m    290\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m output\u001b[38;5;241m.\u001b[39mitems():\n",
      "File \u001b[0;32m~/code/cheap-proteins/src/cheap/esmfold/esmfold.py:260\u001b[0m, in \u001b[0;36mESMFold.folding_trunk\u001b[0;34m(self, s_s_0, s_z_0, aa, residx, mask, num_recycles)\u001b[0m\n\u001b[1;32m    256\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfolding_trunk\u001b[39m(\n\u001b[1;32m    257\u001b[0m     \u001b[38;5;28mself\u001b[39m, s_s_0, s_z_0, aa, residx, mask, num_recycles: T\u001b[38;5;241m.\u001b[39mOptional[\u001b[38;5;28mint\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    258\u001b[0m ):\n\u001b[1;32m    259\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrunk \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 260\u001b[0m     structure: \u001b[38;5;28mdict\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrunk\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    261\u001b[0m \u001b[43m        \u001b[49m\u001b[43ms_s_0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ms_z_0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maa\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresidx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mno_recycles\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_recycles\u001b[49m\n\u001b[1;32m    262\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    263\u001b[0m     structure \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpost_processing(structure, aa, residx, mask)\n\u001b[1;32m    264\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m structure\n",
      "File \u001b[0;32m~/micromamba/envs/plaid/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/micromamba/envs/plaid/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/code/cheap-proteins/src/cheap/esmfold/trunk.py:225\u001b[0m, in \u001b[0;36mFoldingTrunk.forward\u001b[0;34m(self, seq_feats, pair_feats, true_aa, residx, mask, no_recycles)\u001b[0m\n\u001b[1;32m    222\u001b[0m recycle_z \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrecycle_z_norm(recycle_z\u001b[38;5;241m.\u001b[39mdetach())\n\u001b[1;32m    223\u001b[0m recycle_z \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrecycle_disto(recycle_bins\u001b[38;5;241m.\u001b[39mdetach())\n\u001b[0;32m--> 225\u001b[0m s_s, s_z \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrunk_iter\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    226\u001b[0m \u001b[43m    \u001b[49m\u001b[43ms_s_0\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mrecycle_s\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ms_z_0\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mrecycle_z\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresidx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\n\u001b[1;32m    227\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    229\u001b[0m \u001b[38;5;66;03m# === Structure module ===\u001b[39;00m\n\u001b[1;32m    230\u001b[0m sm_s \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrunk2sm_s(s_s)\n",
      "File \u001b[0;32m~/code/cheap-proteins/src/cheap/esmfold/trunk.py:176\u001b[0m, in \u001b[0;36mFoldingTrunk.trunk_iter\u001b[0;34m(self, s, z, residx, mask)\u001b[0m\n\u001b[1;32m    173\u001b[0m z \u001b[38;5;241m=\u001b[39m z \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpairwise_positional_embedding(residx, mask\u001b[38;5;241m=\u001b[39mmask)\n\u001b[1;32m    175\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m block \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblocks:\n\u001b[0;32m--> 176\u001b[0m     s, z \u001b[38;5;241m=\u001b[39m \u001b[43mblock\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    177\u001b[0m \u001b[43m        \u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mz\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresidue_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresidx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunk_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchunk_size\u001b[49m\n\u001b[1;32m    178\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    179\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m s, z\n",
      "File \u001b[0;32m~/micromamba/envs/plaid/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/micromamba/envs/plaid/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/code/cheap-proteins/src/cheap/esmfold/tri_self_attn_block.py:150\u001b[0m, in \u001b[0;36mTriangularSelfAttentionBlock.forward\u001b[0;34m(self, sequence_state, pairwise_state, mask, chunk_size, **_TriangularSelfAttentionBlock__kwargs)\u001b[0m\n\u001b[1;32m    143\u001b[0m pairwise_state \u001b[38;5;241m=\u001b[39m pairwise_state \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrow_drop(\n\u001b[1;32m    144\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtri_mul_out(pairwise_state, mask\u001b[38;5;241m=\u001b[39mtri_mask)\n\u001b[1;32m    145\u001b[0m )\n\u001b[1;32m    146\u001b[0m pairwise_state \u001b[38;5;241m=\u001b[39m pairwise_state \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcol_drop(\n\u001b[1;32m    147\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtri_mul_in(pairwise_state, mask\u001b[38;5;241m=\u001b[39mtri_mask)\n\u001b[1;32m    148\u001b[0m )\n\u001b[1;32m    149\u001b[0m pairwise_state \u001b[38;5;241m=\u001b[39m pairwise_state \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrow_drop(\n\u001b[0;32m--> 150\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtri_att_start\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpairwise_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtri_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunk_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunk_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m )\n\u001b[1;32m    152\u001b[0m pairwise_state \u001b[38;5;241m=\u001b[39m pairwise_state \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcol_drop(\n\u001b[1;32m    153\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtri_att_end(pairwise_state, mask\u001b[38;5;241m=\u001b[39mtri_mask, chunk_size\u001b[38;5;241m=\u001b[39mchunk_size)\n\u001b[1;32m    154\u001b[0m )\n\u001b[1;32m    156\u001b[0m \u001b[38;5;66;03m# MLP over pairs.\u001b[39;00m\n",
      "File \u001b[0;32m~/micromamba/envs/plaid/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/micromamba/envs/plaid/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/openfold/openfold/model/triangular_attention.py:128\u001b[0m, in \u001b[0;36mTriangleAttention.forward\u001b[0;34m(self, x, mask, chunk_size, use_memory_efficient_kernel, use_lma, inplace_safe)\u001b[0m\n\u001b[1;32m    125\u001b[0m biases \u001b[38;5;241m=\u001b[39m [mask_bias, triangle_bias]\n\u001b[1;32m    127\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunk_size \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 128\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_chunk\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    129\u001b[0m \u001b[43m        \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    130\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbiases\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    131\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunk_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    132\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_memory_efficient_kernel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_memory_efficient_kernel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    133\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_lma\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_lma\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    134\u001b[0m \u001b[43m        \u001b[49m\u001b[43minplace_safe\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minplace_safe\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    135\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    137\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmha(\n\u001b[1;32m    138\u001b[0m         q_x\u001b[38;5;241m=\u001b[39mx, \n\u001b[1;32m    139\u001b[0m         kv_x\u001b[38;5;241m=\u001b[39mx, \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    142\u001b[0m         use_lma\u001b[38;5;241m=\u001b[39muse_lma\n\u001b[1;32m    143\u001b[0m     )\n",
      "File \u001b[0;32m~/openfold/openfold/model/triangular_attention.py:76\u001b[0m, in \u001b[0;36mTriangleAttention._chunk\u001b[0;34m(self, x, biases, chunk_size, use_memory_efficient_kernel, use_lma, inplace_safe)\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtriangle! triangle!\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     70\u001b[0m mha_inputs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     71\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mq_x\u001b[39m\u001b[38;5;124m\"\u001b[39m: x,\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkv_x\u001b[39m\u001b[38;5;124m\"\u001b[39m: x,\n\u001b[1;32m     73\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbiases\u001b[39m\u001b[38;5;124m\"\u001b[39m: biases,\n\u001b[1;32m     74\u001b[0m }\n\u001b[0;32m---> 76\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mchunk_layer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     77\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     78\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmha\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     79\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_memory_efficient_kernel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_memory_efficient_kernel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     80\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_lma\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_lma\u001b[49m\n\u001b[1;32m     81\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     82\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmha_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     83\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunk_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunk_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     84\u001b[0m \u001b[43m    \u001b[49m\u001b[43mno_batch_dims\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     85\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_out\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43minplace_safe\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     86\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/openfold/openfold/utils/chunk_utils.py:264\u001b[0m, in \u001b[0;36mchunk_layer\u001b[0;34m(layer, inputs, chunk_size, no_batch_dims, low_mem, _out, _add_into_out)\u001b[0m\n\u001b[1;32m    261\u001b[0m         t \u001b[38;5;241m=\u001b[39m t\u001b[38;5;241m.\u001b[39mexpand(orig_batch_dims \u001b[38;5;241m+\u001b[39m t\u001b[38;5;241m.\u001b[39mshape[no_batch_dims:])\n\u001b[1;32m    262\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\n\u001b[0;32m--> 264\u001b[0m prepped_inputs \u001b[38;5;241m=\u001b[39m tensor_tree_map(_prep_inputs, inputs)\n\u001b[1;32m    265\u001b[0m prepped_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    266\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m(_out \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m):\n",
      "File \u001b[0;32m~/openfold/openfold/utils/tensor_utils.py:109\u001b[0m, in \u001b[0;36mtree_map\u001b[0;34m(fn, tree, leaf_type)\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtree_map\u001b[39m(fn, tree, leaf_type):\n\u001b[1;32m    108\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(tree, \u001b[38;5;28mdict\u001b[39m):\n\u001b[0;32m--> 109\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdict_map\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtree\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mleaf_type\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    110\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(tree, \u001b[38;5;28mlist\u001b[39m):\n\u001b[1;32m    111\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [tree_map(fn, x, leaf_type) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m tree]\n",
      "File \u001b[0;32m~/openfold/openfold/utils/tensor_utils.py:102\u001b[0m, in \u001b[0;36mdict_map\u001b[0;34m(fn, dic, leaf_type)\u001b[0m\n\u001b[1;32m    100\u001b[0m         new_dict[k] \u001b[38;5;241m=\u001b[39m dict_map(fn, v, leaf_type)\n\u001b[1;32m    101\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 102\u001b[0m         new_dict[k] \u001b[38;5;241m=\u001b[39m \u001b[43mtree_map\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mleaf_type\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    104\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m new_dict\n",
      "File \u001b[0;32m~/openfold/openfold/utils/tensor_utils.py:111\u001b[0m, in \u001b[0;36mtree_map\u001b[0;34m(fn, tree, leaf_type)\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m dict_map(fn, tree, leaf_type)\n\u001b[1;32m    110\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(tree, \u001b[38;5;28mlist\u001b[39m):\n\u001b[0;32m--> 111\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [tree_map(fn, x, leaf_type) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m tree]\n\u001b[1;32m    112\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(tree, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m    113\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m([tree_map(fn, x, leaf_type) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m tree])\n",
      "File \u001b[0;32m~/openfold/openfold/utils/tensor_utils.py:111\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m dict_map(fn, tree, leaf_type)\n\u001b[1;32m    110\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(tree, \u001b[38;5;28mlist\u001b[39m):\n\u001b[0;32m--> 111\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[43mtree_map\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mleaf_type\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m tree]\n\u001b[1;32m    112\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(tree, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m    113\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m([tree_map(fn, x, leaf_type) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m tree])\n",
      "File \u001b[0;32m~/openfold/openfold/utils/tensor_utils.py:115\u001b[0m, in \u001b[0;36mtree_map\u001b[0;34m(fn, tree, leaf_type)\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m([tree_map(fn, x, leaf_type) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m tree])\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(tree, leaf_type):\n\u001b[0;32m--> 115\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtree\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    117\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mtype\u001b[39m(tree))\n",
      "File \u001b[0;32m~/openfold/openfold/utils/chunk_utils.py:259\u001b[0m, in \u001b[0;36mchunk_layer.<locals>._prep_inputs\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    257\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28msum\u001b[39m(t\u001b[38;5;241m.\u001b[39mshape[:no_batch_dims]) \u001b[38;5;241m==\u001b[39m no_batch_dims:\n\u001b[1;32m    258\u001b[0m         t \u001b[38;5;241m=\u001b[39m t\u001b[38;5;241m.\u001b[39mexpand(orig_batch_dims \u001b[38;5;241m+\u001b[39m t\u001b[38;5;241m.\u001b[39mshape[no_batch_dims:])\n\u001b[0;32m--> 259\u001b[0m     t \u001b[38;5;241m=\u001b[39m \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[43mno_batch_dims\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    260\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    261\u001b[0m     t \u001b[38;5;241m=\u001b[39m t\u001b[38;5;241m.\u001b[39mexpand(orig_batch_dims \u001b[38;5;241m+\u001b[39m t\u001b[38;5;241m.\u001b[39mshape[no_batch_dims:])\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 8.00 GiB. GPU "
     ]
    }
   ],
   "source": [
    "pdb_strs, raw_outputs = latent_to_structure.to_structure(sampled_unscaled, return_raw_outputs=True, sequences=sequences, batch_size=32, num_recycles=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cad56f46-1950-495f-9884-6575c0e9a64f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "_ = sns.distplot(raw_outputs['plddt'].mean(dim=-1).mean(dim=-1).cpu().numpy(), bins=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87165734-415d-47f3-ad0f-9edbb69a8fb2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import py3Dmol\n",
    "\n",
    "# for i in range(len(pdb_strs)):\n",
    "# for i in range(10,20): \n",
    "# for i in range(0, 10): \n",
    "for i in range(20,30): \n",
    "    view = py3Dmol.view(width=600, height=600)\n",
    "    view.addModelsAsFrames(pdb_strs[i])\n",
    "    \n",
    "    # Apply the plDDT color scheme\n",
    "    # view.setStyle({'cartoon': {'color': {'prop': 'b', 'gradient': 'roygb', 'min': 0, 'max': 100}}})\n",
    "    view.setStyle({'cartoon': {'color': {'prop': 'b', 'gradient': 'roygb', 'min': 50, 'max': 90}}})\n",
    "    \n",
    "    # # Add surface representation with plDDT-based color\n",
    "    view.addSurface(py3Dmol.VDW, {'opacity': 0.7, 'colorscheme': {'prop': 'b', 'gradient': 'roygb', 'min': 50, 'max': 90}})\n",
    "    # view.addSurface(py3Dmol.VDW, {'opacity': 0.7, 'colorscheme': {'prop': 'b', 'gradient': 'roygb', 'min': 0, 'max': 100}})\n",
    "\n",
    "    view.zoomTo()\n",
    "    view.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c15f4adf-d61c-47e7-afa6-08619861e4a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from plaid.evaluation import RITAPerplexity\n",
    "\n",
    "perplexity_calc = RITAPerplexity(device=device)\n",
    "perplexities = perplexity_calc.batch_eval(sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69a3cd6d-9fbb-48b8-bb2e-e824f985020c",
   "metadata": {},
   "outputs": [],
   "source": [
    "perplexities = [perplexity_calc.calc_perplexity(s) for s in sequences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8db437c2-58e1-4121-9bdc-7d57f6353864",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "_ = sns.distplot(perplexities, bins=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaf6a69e-c3c4-4bca-b5c5-59f367b7abca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc89dcc9-dc2f-4cf5-82af-d3a1b6e61a02",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ba241a5-a334-4034-aabd-186e81be9028",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "183f2690-b3f0-40f0-97bf-5cdd89196245",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (plaid)",
   "language": "python",
   "name": "plaid"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
