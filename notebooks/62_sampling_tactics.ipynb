{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4f5585dc-b641-4086-886f-61d3f30b6aba",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a178beeb-aaf6-459a-9b46-0d06e3c96ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from plaid.constants import ICLR_MODEL_ID\n",
    "import typing as T\n",
    "from pathlib import Path\n",
    "from omegaconf import OmegaConf\n",
    "\n",
    "from plaid.diffusion import FunctionOrganismDiffusion\n",
    "from plaid.denoisers import FunctionOrganismDiT, FunctionOrganismUDiT, DenoiserKwargs\n",
    "from plaid.constants import COMPRESSION_INPUT_DIMENSIONS\n",
    "from plaid.datasets import NUM_ORGANISM_CLASSES, NUM_FUNCTION_CLASSES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9b4f417d-acc4-4b10-9f1e-cfbb33698b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = ICLR_MODEL_ID\n",
    "model_ckpt_dir  = Path(\"/data/lux70/plaid/checkpoints/plaid-compositional\")\n",
    "model_path = model_ckpt_dir / model_id / \"last.ckpt\"\n",
    "\n",
    "organism_idx: int = NUM_ORGANISM_CLASSES\n",
    "function_idx: int = NUM_FUNCTION_CLASSES\n",
    "cond_scale: float = 7\n",
    "num_samples: int = -1\n",
    "beta_scheduler_name: T.Optional[str] = \"sigmoid\"\n",
    "sampling_timesteps: int = 20 \n",
    "batch_size: int = -1\n",
    "length: int = 32  # the final length, after decoding back to structure/sequence, is twice this value\n",
    "return_all_timesteps: bool = False\n",
    "\n",
    "config_path = model_ckpt_dir / model_id / \"config.yaml\"\n",
    "\n",
    "cfg = OmegaConf.load(config_path)\n",
    "compression_model_id = cfg['compression_model_id']\n",
    "# shorten_factor = COMPRESSION_SHORTEN_FACTORS[compression_model_id]\n",
    "input_dim = COMPRESSION_INPUT_DIMENSIONS[compression_model_id]\n",
    "\n",
    "# instantiate the correct denoiser class\n",
    "# UDiT supports skip connections and memory-efficient attention, while DiT does not\n",
    "denoiser_kwargs = cfg.denoiser\n",
    "denoiser_class = denoiser_kwargs.pop(\"_target_\")\n",
    "\n",
    "if denoiser_class == \"plaid.denoisers.FunctionOrganismUDiT\":\n",
    "    denoiser = FunctionOrganismUDiT(**denoiser_kwargs, input_dim=input_dim)\n",
    "elif denoiser_class == \"plaid.denoisers.FunctionOrganismDiT\":\n",
    "    denoiser = FunctionOrganismDiT(**denoiser_kwargs, input_dim=input_dim)\n",
    "else:\n",
    "    raise ValueError(f\"Unknown denoiser class: {denoiser_class}\")\n",
    "\n",
    "# lask.ckpt automatically links to the EMA\n",
    "ckpt = torch.load(model_path)\n",
    "\n",
    "# remove the prefix from the state dict if torch.compile was used during training\n",
    "mod_state_dict = {}\n",
    "for k, v in ckpt['state_dict'].items():\n",
    "    if k[:16] == \"model._orig_mod.\":\n",
    "        mod_state_dict[k[16:]] = v\n",
    "\n",
    "# load weights and create diffusion object\n",
    "denoiser.load_state_dict(mod_state_dict)\n",
    "diffusion_kwargs = cfg.diffusion\n",
    "diffusion_kwargs.pop(\"_target_\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9e3668d8-e3ed-4efd-ad78-e5818e107bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from diffusers import LMSDiscreteScheduler\n",
    "\n",
    "scheduler = LMSDiscreteScheduler(beta_start=0.00085, beta_end=0.012, beta_schedule=\"scaled_linear\", num_train_timesteps=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ed55b9c1-8a17-4f16-b68f-de7b4b97ee78",
   "metadata": {},
   "outputs": [],
   "source": [
    "height = 512                        # default height of Stable Diffusion\n",
    "width = 512                         # default width of Stable Diffusion\n",
    "\n",
    "num_inference_steps = 100           # Number of denoising steps\n",
    "\n",
    "guidance_scale = 7.5                # Scale for classifier-free guidance\n",
    "\n",
    "generator = torch.manual_seed(0)    # Seed generator to create the inital latent noise\n",
    "\n",
    "batch_size = 8\n",
    "scheduler.set_timesteps(num_inference_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fec6916-12e8-4a64-8333-75332cf5142f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cde50282-80bf-48f2-897d-3accbca68006",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02f8ae7da9e34b57b410702ffc2db0bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "scheduler.set_timesteps(num_inference_steps)\n",
    "\n",
    "for t in tqdm(scheduler.timesteps):\n",
    "    # # expand the latents if we are doing classifier-free guidance to avoid doing two forward passes.\n",
    "    # latent_model_input = torch.cat([latents] * 2)\n",
    "\n",
    "    # latent_model_input = scheduler.scale_model_input(latent_model_input, timestep=t)\n",
    "\n",
    "    # # predict the noise residual\n",
    "    # with torch.no_grad():\n",
    "    #     noise_pred = unet(latent_model_input, t, encoder_hidden_states=text_embeddings).sample\n",
    "\n",
    "    # # perform guidance\n",
    "    # noise_pred_uncond, noise_pred_text = noise_pred.chunk(2)\n",
    "    # noise_pred = noise_pred_uncond + guidance_scale * (noise_pred_text - noise_pred_uncond)\n",
    "\n",
    "    # # compute the previous noisy sample x_t -> x_t-1\n",
    "    # latents = scheduler.step(noise_pred, t, latents).prev_sample\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc8d3ec1-c9c0-4ad3-bc23-175cb56ba750",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (plaid-train)",
   "language": "python",
   "name": "plaid-train"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
