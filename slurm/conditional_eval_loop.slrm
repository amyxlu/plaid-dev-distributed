#!/usr/bin/env bash

#SBATCH --job-name conditional 
#SBATCH --nodes 1 
#SBATCH --gpus-per-node 1 
#SBATCH --partition gpu2
#SBATCH --cpus-per-gpu 2 
#SBATCH --mem 80G
#SBATCH --time=15-00:00:00

eval "$(conda shell.bash hook)"

micromamba activate omegafold

echo "SLURM_JOB_ID = ${SLURM_JOB_ID}"

export HYDRA_FULL_ERROR=1

cd /homefs/home/lux70/code/plaid

nvidia-smi

# Line counter
line_number=0
start_idx=$1
end_idx=$2

while IFS= read -r idx; do
    ((line_number++))

    # Skip lines before 100
    if (( line_number < $start_idx )); then
        continue
    fi

    # Stop after line 200
    if (( line_number > $end_idx )); then
        break
    fi

    function_idx="$idx"
    echo "Processing line number: $line_number"
    echo "Processing index: $function_idx"

    if [[ -z "$idx" ]]; then
        continue
    fi

    srun python evaluation_pipeline.py experiment=dpm ++sample.cond_scale=8. ++sample.sampling_timesteps=20 ++sample.function_idx=$function_idx

done < GO_idxs.txt


