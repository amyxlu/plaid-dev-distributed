#!/usr/bin/env bash

#SBATCH --job-name pgbaseline 
#SBATCH --nodes 1 
#SBATCH --gpus-per-node 1 
#SBATCH --partition gpu2
#SBATCH --cpus-per-gpu 4 
#SBATCH --mem 100G
#SBATCH --time=15-00:00:00

eval "$(conda shell.bash hook)"

echo "SLURM_JOB_NODELIST = ${SLURM_JOB_NODELIST}"
echo "SLURM_JOB_ID = ${SLURM_JOB_ID}"
echo "SLURMD_NODENAME = ${SLURMD_NODENAME}"
echo "SLURM_JOB_NUM_NODES = ${SLURM_JOB_NUM_NODES}"

source /homefs/home/lux70/.bashrc

export HYDRA_FULL_ERROR=1
nvidia-smi

micromamba activate proteingenerator

minlen=$1
maxlen=$2

for (( i=$1; i<=$2; i+=8 ))
do

cd /homefs/home/lux70/code/protein_generator/

srun python inference.py \
    --num_designs 64 \
    --out /data/lux70/plaid/baselines/proteingenerator/generated/structures/len$i \
    --length $i \
    --T 25 \
    --contigs $i \
    --checkpoint weights/SEQDIFF_221219_equalTASKS_nostrSELFCOND_mod30.pt \
    --save_best_plddt
done

python inference.py \
    --num_designs 100 \
    --out /data/lux70/plaid/baselines/proteingenerator/generated/structures/len$i \
    --length $i \
    --T 25 \
    --contigs $i \
    --checkpoint weights/SEQDIFF_221219_equalTASKS_nostrSELFCOND_mod30.pt \
    --save_best_plddt
done

